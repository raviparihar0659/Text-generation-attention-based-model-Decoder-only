{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hGyPXWYctRya"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "8hvWruK9utmI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    PyTorch module that converts tokens into embeddings.\n",
        "\n",
        "    Input dimension is: (batch_size, sequence_length)\n",
        "    Output dimension is: (batch_size, sequence_length, d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, number_of_tokens):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = torch.nn.Embedding(\n",
        "            num_embeddings=number_of_tokens,\n",
        "            embedding_dim=d_model\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding_layer(x)\n"
      ],
      "metadata": {
        "id": "Ha_wA4rstpDB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module that creates a positional encoding matrix. This matrix will later be added to the\n",
        "    transformer's input embeddings to provide a sense of position of the sequence elements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.positional_encoding = self.create_positional_encoding()\n",
        "\n",
        "    def create_positional_encoding(self):\n",
        "        \"\"\"\n",
        "        Creates a positional encoding matrix of size (max_sequence_length, d_model).\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize positional encoding matrix\n",
        "        positional_encoding = np.zeros((self.max_sequence_length, self.d_model))\n",
        "\n",
        "        # Calculate positional encoding for each position and each dimension\n",
        "        for pos in range(self.max_sequence_length):\n",
        "            for i in range(0, self.d_model, 2):\n",
        "                # Apply sin to even indices in the array; indices in Python start at 0 so i is even.\n",
        "                positional_encoding[pos, i] = np.sin(pos / (10000 ** ((2 * i) / self.d_model)))\n",
        "\n",
        "                if i + 1 < self.d_model:\n",
        "                    # Apply cos to odd indices in the array; we add 1 to i because indices in Python start at 0.\n",
        "                    positional_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((2 * i) / self.d_model)))\n",
        "\n",
        "        # Convert numpy array to PyTorch tensor and return it\n",
        "        return torch.from_numpy(positional_encoding).float().to(get_device())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Adds the positional encoding to the input embeddings at the corresponding positions.\n",
        "        \"\"\"\n",
        "        # Add positional encodings to input embeddings. The \":\" indexing ensures we only add positional encodings up\n",
        "        # to the length of the sequence in the batch. x.size(0) is the batch size, so this is a way to make sure\n",
        "        # we're not adding extra positional encodings.\n",
        "        return x + self.positional_encoding[:x.size(1), :]\n"
      ],
      "metadata": {
        "id": "-OZ5ADgXtpGA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSelfAttention(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module for a self attention layer.\n",
        "    This layer is used in the MultiHeadedSelfAttention module.\n",
        "\n",
        "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
        "    Output dimension is: (batch_size, sequence_length, head_dimension)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dimension, head_dimension):\n",
        "        super().__init__()\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.head_dimension = head_dimension\n",
        "        self.query_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
        "        self.key_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
        "        self.value_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Compute the self attention.\n",
        "\n",
        "        x dimension is: (batch_size, sequence_length, embedding_dimension)\n",
        "        output dimension is: (batch_size, sequence_length, head_dimension)\n",
        "        mask dimension is: (batch_size, sequence_length)\n",
        "\n",
        "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
        "        \"\"\"\n",
        "\n",
        "        # x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        # query, key, value dimensions are: (batch_size, sequence_length, head_dimension)\n",
        "        query = self.query_layer(x)\n",
        "        key = self.key_layer(x)\n",
        "        value = self.value_layer(x)\n",
        "\n",
        "        # Calculate the attention weights.\n",
        "        # attention_weights dimensions are: (batch_size, sequence_length, sequence_length)\n",
        "        attention_weights = torch.matmul(query, key.transpose(-2, -1))\n",
        "\n",
        "        # Scale the attention weights.\n",
        "        attention_weights = attention_weights / np.sqrt(self.head_dimension)\n",
        "\n",
        "        # Apply the mask to the attention weights, by setting the masked tokens to a very low value.\n",
        "        # This will make the softmax output 0 for these values.\n",
        "        mask = mask.reshape(attention_weights.shape[0], 1, attention_weights.shape[2])\n",
        "        attention_weights = attention_weights.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Softmax makes sure all scores are between 0 and 1 and the sum of scores is 1.\n",
        "        # attention_scores dimensions are: (batch_size, sequence_length, sequence_length)\n",
        "        attention_scores = self.softmax(attention_weights)\n",
        "\n",
        "        # The attention scores are multiplied by the value\n",
        "        # Values of tokens with high attention score get highlighted because they are multiplied by a larger number,\n",
        "        # and tokens with low attention score get drowned out because they are multiplied by a smaller number.\n",
        "        # Output dimensions are: (batch_size, sequence_length, head_dimension)\n",
        "        return torch.bmm(attention_scores, value)\n",
        "\n"
      ],
      "metadata": {
        "id": "R-z2QQ_StpJU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedMultiHeadedSelfAttention(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module for a multi head attention layer.\n",
        "\n",
        "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
        "    Output dimension is: (batch_size, sequence_length, embedding_dimension)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dimension, number_of_heads):\n",
        "        super().__init__()\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.head_dimension = embedding_dimension // number_of_heads\n",
        "        self.number_of_heads = number_of_heads\n",
        "\n",
        "        # Create the self attention modules\n",
        "        self.self_attentions = torch.nn.ModuleList(\n",
        "            [MaskedSelfAttention(embedding_dimension, self.head_dimension) for _ in range(number_of_heads)])\n",
        "\n",
        "        # Create a linear layer to combine the outputs of the self attention modules\n",
        "        self.output_layer = torch.nn.Linear(number_of_heads * self.head_dimension, embedding_dimension)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Compute the multi head attention.\n",
        "\n",
        "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        mask dimensions are: (batch_size, sequence_length)\n",
        "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
        "        \"\"\"\n",
        "        # Compute the self attention for each head\n",
        "        # self_attention_outputs dimensions are:\n",
        "        # (number_of_heads, batch_size, sequence_length, head_dimension)\n",
        "        self_attention_outputs = [self_attention(x, mask) for self_attention in self.self_attentions]\n",
        "\n",
        "        # Concatenate the self attention outputs\n",
        "        # self_attention_outputs_concatenated dimensions are:\n",
        "        # (batch_size, sequence_length, number_of_heads * head_dimension)\n",
        "        concatenated_self_attention_outputs = torch.cat(self_attention_outputs, dim=2)\n",
        "\n",
        "        # Apply the output layer to the concatenated self attention outputs\n",
        "        # output dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        return self.output_layer(concatenated_self_attention_outputs)\n"
      ],
      "metadata": {
        "id": "EPYMHm21tpQG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module for a feed forward layer.\n",
        "\n",
        "    A feed forward layer is a fully connected layer with a ReLU activation function in between.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dimension, feed_forward_dimension):\n",
        "        super().__init__()\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.feed_forward_dimension = feed_forward_dimension\n",
        "        self.linear_1 = torch.nn.Linear(embedding_dimension, feed_forward_dimension)\n",
        "        self.linear_2 = torch.nn.Linear(feed_forward_dimension, embedding_dimension)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Compute the feed forward layer.\n",
        "        \"\"\"\n",
        "        return self.linear_2(torch.relu(self.linear_1(x)))\n"
      ],
      "metadata": {
        "id": "nZTTrfC2tpS9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module for an encoder layer.\n",
        "\n",
        "    An encoder layer consists of a multi-headed self attention layer, a feed forward layer and dropout.\n",
        "\n",
        "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
        "    Output dimension is: (batch_size, sequence_length, embedding_dimension)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            embedding_dimension,\n",
        "            number_of_heads,\n",
        "            feed_forward_dimension,\n",
        "            dropout_rate\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.number_of_heads = number_of_heads\n",
        "        self.feed_forward_dimension = feed_forward_dimension\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.multi_headed_self_attention = MaskedMultiHeadedSelfAttention(embedding_dimension, number_of_heads)\n",
        "        self.feed_forward = FeedForward(embedding_dimension, feed_forward_dimension)\n",
        "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
        "        self.layer_normalization_1 = torch.nn.LayerNorm(embedding_dimension)\n",
        "        self.layer_normalization_2 = torch.nn.LayerNorm(embedding_dimension)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Compute the encoder layer.\n",
        "\n",
        "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        mask dimensions are: (batch_size, sequence_length)\n",
        "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
        "        \"\"\"\n",
        "\n",
        "        # Layer normalization 1\n",
        "        normalized_x = self.layer_normalization_1(x)\n",
        "\n",
        "        # Multi headed self attention\n",
        "        attention_output = self.multi_headed_self_attention(normalized_x, mask)\n",
        "\n",
        "        # Residual output\n",
        "        residual_output = x + attention_output\n",
        "\n",
        "        # Layer normalization 2\n",
        "        normalized_residual_output = self.layer_normalization_2(residual_output)\n",
        "\n",
        "        # Feed forward\n",
        "        feed_forward_output = self.feed_forward(normalized_residual_output)\n",
        "\n",
        "        # Dropout\n",
        "        if self.training:\n",
        "            feed_forward_output = self.dropout(feed_forward_output)\n",
        "\n",
        "        # Residual output\n",
        "        return residual_output + feed_forward_output\n",
        "\n"
      ],
      "metadata": {
        "id": "po_IBLrbtpVc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderStack(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The decoder stack consists of multiple decoder layers in sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            embedding_dimension,\n",
        "            number_of_layers,\n",
        "            number_of_heads,\n",
        "            feed_forward_dimension,\n",
        "            dropout_rate,\n",
        "            max_sequence_length\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.number_of_layers = number_of_layers\n",
        "        self.number_of_heads = number_of_heads\n",
        "        self.feed_forward_dimension = feed_forward_dimension\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "\n",
        "        # Create the encoder layers\n",
        "        self.encoder_layers = torch.nn.ModuleList(\n",
        "            [DecoderLayer(embedding_dimension, number_of_heads, feed_forward_dimension, dropout_rate) for _ in\n",
        "             range(number_of_layers)])\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        decoder_outputs = x\n",
        "        for decoder_layer in self.encoder_layers:\n",
        "            decoder_outputs = decoder_layer(decoder_outputs, mask)\n",
        "\n",
        "        return decoder_outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "8vENFUW2tpYO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMHead(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module for the language model head.\n",
        "    The language model head is a linear layer that maps the embedding dimension to the vocabulary size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dimension, number_of_tokens):\n",
        "        super().__init__()\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.number_of_tokens = number_of_tokens\n",
        "        self.linear = torch.nn.Linear(embedding_dimension, number_of_tokens)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Compute the language model head.\n",
        "\n",
        "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        output dimensions are: (batch_size, sequence_length, number_of_tokens)\n",
        "        \"\"\"\n",
        "        # Compute the linear layer\n",
        "        # linear_output dimensions are: (batch_size, sequence_length, number_of_tokens)\n",
        "        linear_output = self.linear(x)\n",
        "\n",
        "        return linear_output\n",
        "\n"
      ],
      "metadata": {
        "id": "_z8e8UUwtpav"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module for a language model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            number_of_tokens,  # The number of tokens in the vocabulary\n",
        "            max_sequence_length=512,  # The maximum sequence length to use for attention\n",
        "            embedding_dimension=512,  # The dimension of the token embeddings\n",
        "            number_of_layers=6,  # The number of decoder layers to use\n",
        "            number_of_heads=4,  # The number of attention heads to use\n",
        "            feed_forward_dimension=None,  # The dimension of the feed forward layer\n",
        "            dropout_rate=0.1  # The dropout rate to use\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.number_of_tokens = number_of_tokens\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.number_of_layers = number_of_layers\n",
        "        self.number_of_heads = number_of_heads\n",
        "\n",
        "        if feed_forward_dimension is None:\n",
        "            # GPT-2 paper uses 4 * embedding_dimension for the feed forward dimension\n",
        "            self.feed_forward_dimension = embedding_dimension * 4\n",
        "        else:\n",
        "            self.feed_forward_dimension = feed_forward_dimension\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        # Create the token embedding layer\n",
        "        self.token_embedding = TokenEmbedding(embedding_dimension, number_of_tokens)\n",
        "\n",
        "        # Create the positional encoding layer\n",
        "        self.positional_encoding = PositionalEncoding(embedding_dimension, max_sequence_length)\n",
        "\n",
        "        # Create the normalization layer\n",
        "        self.layer_normalization = torch.nn.LayerNorm(embedding_dimension)\n",
        "\n",
        "        # Create the decoder stack\n",
        "        self.decoder = DecoderStack(\n",
        "            embedding_dimension=embedding_dimension,\n",
        "            number_of_layers=number_of_layers,\n",
        "            number_of_heads=number_of_heads,\n",
        "            feed_forward_dimension=self.feed_forward_dimension,\n",
        "            dropout_rate=dropout_rate,\n",
        "            max_sequence_length=max_sequence_length\n",
        "        )\n",
        "\n",
        "        # Create the language model head\n",
        "        self.lm_head = LMHead(embedding_dimension, number_of_tokens)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Compute the token embeddings\n",
        "        # token_embeddings dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        token_embeddings = self.token_embedding(x)\n",
        "\n",
        "        # Compute the positional encoding\n",
        "        # positional_encoding dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
        "        positional_encoding = self.positional_encoding(token_embeddings)\n",
        "\n",
        "        # Post embedding layer normalization\n",
        "        positional_encoding_normalized = self.layer_normalization(positional_encoding)\n",
        "\n",
        "        decoder_outputs = self.decoder(positional_encoding_normalized, mask)\n",
        "        lm_head_outputs = self.lm_head(decoder_outputs)\n",
        "\n",
        "        return lm_head_outputs\n",
        "\n",
        "    def save_checkpoint(self, path):\n",
        "        print(f'Saving checkpoint {path}')\n",
        "        torch.save({\n",
        "            'number_of_tokens': self.number_of_tokens,\n",
        "            'max_sequence_length': self.max_sequence_length,\n",
        "            'embedding_dimension': self.embedding_dimension,\n",
        "            'number_of_layers': self.number_of_layers,\n",
        "            'number_of_heads': self.number_of_heads,\n",
        "            'feed_forward_dimension': self.feed_forward_dimension,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'model_state_dict': self.state_dict()\n",
        "        }, path)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_checkpoint(path) -> 'LanguageModel':\n",
        "        checkpoint = torch.load(path)\n",
        "        model = LanguageModel(\n",
        "            number_of_tokens=checkpoint['number_of_tokens'],\n",
        "            max_sequence_length=checkpoint['max_sequence_length'],\n",
        "            embedding_dimension=checkpoint['embedding_dimension'],\n",
        "            number_of_layers=checkpoint['number_of_layers'],\n",
        "            number_of_heads=checkpoint['number_of_heads'],\n",
        "            feed_forward_dimension=checkpoint['feed_forward_dimension'],\n",
        "            dropout_rate=checkpoint['dropout_rate']\n",
        "        )\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        return model.to(get_device())\n",
        "\n"
      ],
      "metadata": {
        "id": "qAcR01nGtpdX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoregressiveWrapper(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Pytorch module that wraps a GPT model and makes it autoregressive.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gpt_model):\n",
        "        super().__init__()\n",
        "        self.model = gpt_model\n",
        "        self.max_sequence_length = self.model.max_sequence_length\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Autoregressive forward pass\n",
        "        \"\"\"\n",
        "        inp, target = x[:, :-1], x[:, 1:]\n",
        "        mask = mask[:, :-1]\n",
        "\n",
        "        output = self.model(inp, mask)\n",
        "        return output, target\n",
        "\n",
        "    def next_token_probabilities(self, x, mask, temperature=1.0):\n",
        "        \"\"\"\n",
        "        Calculate the token probabilities for the next token in the sequence.\n",
        "        \"\"\"\n",
        "        logits = self.model(x, mask)[:, -1]\n",
        "\n",
        "        # Apply temperature\n",
        "        if temperature != 1.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "        # Apply the softmax\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        return probabilities\n",
        "\n",
        "    def save_checkpoint(self, path):\n",
        "        self.model.save_checkpoint(path)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_checkpoint(path) -> 'AutoregressiveWrapper':\n",
        "        model = LanguageModel.load_checkpoint(path)\n",
        "        return AutoregressiveWrapper(model).to(get_device())\n"
      ],
      "metadata": {
        "id": "KYGDfR8Ttpfl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dictionary = {}\n",
        "        self.reverse_dictionary = {}\n",
        "\n",
        "        # Add the padding token\n",
        "        self.__add_to_dict('<pad>')\n",
        "\n",
        "        # Add characters and numbers to the dictionary\n",
        "        for i in range(10):\n",
        "            self.__add_to_dict(str(i))\n",
        "        for i in range(26):\n",
        "            self.__add_to_dict(chr(ord('a') + i))\n",
        "\n",
        "\n",
        "        # Add space and punctuation to the dictionary\n",
        "        self.__add_to_dict('.')\n",
        "        self.__add_to_dict(' ')\n",
        "        self.__add_to_dict(',')\n",
        "        self.__add_to_dict('’')\n",
        "        self.__add_to_dict('?')\n",
        "        self.__add_to_dict('!')\n",
        "\n",
        "\n",
        "    def __add_to_dict(self, character):\n",
        "        if character not in self.dictionary:\n",
        "            self.dictionary[character] = len(self.dictionary)\n",
        "            self.reverse_dictionary[self.dictionary[character]] = character\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return [self.dictionary[c] for c in text]\n",
        "\n",
        "    def character_to_token(self, character):\n",
        "        return self.dictionary[character]\n",
        "\n",
        "    def token_to_character(self, token):\n",
        "        return self.reverse_dictionary[token]\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.dictionary)\n",
        "\n"
      ],
      "metadata": {
        "id": "zcc87jVQtpi3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, tokenizer: Tokenizer, optimizer=None):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        if optimizer is None:\n",
        "            self.optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "        else:\n",
        "            self.optimizer = optimizer\n",
        "        self.tokenizer = tokenizer\n",
        "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def train(self, data: List[str], epochs, batch_size):\n",
        "        loss_per_epoch = []\n",
        "        for epoch in range(epochs):\n",
        "            losses = []\n",
        "\n",
        "            # Shuffle the sequences\n",
        "            random.shuffle(data)\n",
        "\n",
        "            # Create batches of sequences and their respective mask.\n",
        "            batches = []\n",
        "            for i in range(0, len(data), batch_size):\n",
        "                sequence_tensor = torch.tensor(data[i: i + batch_size], dtype=torch.long)\n",
        "\n",
        "                # Create the mask tensor for the batch, where 1 means the token is not a padding token\n",
        "                mask_tensor = torch.ones_like(sequence_tensor)\n",
        "                mask_tensor[sequence_tensor == self.tokenizer.character_to_token('<pad>')] = 0\n",
        "\n",
        "                batches.append((sequence_tensor, mask_tensor))\n",
        "\n",
        "            # Train the model on each batch\n",
        "            for batch in batches:\n",
        "                self.model.train()\n",
        "\n",
        "                # Create the input and mask tensors\n",
        "                input_tensor = torch.zeros((batch_size, self.model.max_sequence_length + 1), dtype=torch.long)\n",
        "                mask_tensor = torch.zeros((batch_size, self.model.max_sequence_length + 1), dtype=torch.long)\n",
        "\n",
        "                for i, input_entry in enumerate(batch[0]):\n",
        "                    input_tensor[i] = input_entry\n",
        "\n",
        "                for i, mask_entry in enumerate(batch[1]):\n",
        "                    mask_tensor[i] = mask_entry\n",
        "\n",
        "                # Compute the model output\n",
        "                model_output, target = self.model.forward(\n",
        "                    x=input_tensor.to(get_device()),\n",
        "                    mask=mask_tensor.to(get_device())\n",
        "                )\n",
        "\n",
        "                # Compute the losses\n",
        "                # The loss is computed on the model output and the target\n",
        "                loss = self.loss_function(model_output.transpose(1, 2), target)\n",
        "                # loss = self.loss_function(model_output[:, -1, :], target[:, -1])\n",
        "\n",
        "                # Backpropagate the loss.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the gradients. This is used to prevent exploding gradients.\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
        "\n",
        "                # Update the model parameters. This is done by taking a step in the direction of the gradient.\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Reset the gradients. This is done so that the gradients from the previous batch\n",
        "                # are not used in the next step.\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Append the loss to the list of losses, so that the average loss can be computed for this epoch.\n",
        "                losses.append(loss.item())\n",
        "\n",
        "            # Print the loss\n",
        "            epoch_loss = np.average(losses)\n",
        "            loss_per_epoch.append(epoch_loss)\n",
        "            print('Epoch:', epoch, 'Loss:', epoch_loss)\n",
        "\n",
        "        return loss_per_epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "rgs1chdUuw1C"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            model,\n",
        "            tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def generate(\n",
        "            self,\n",
        "            max_tokens_to_generate: int,\n",
        "            prompt: str = None,\n",
        "            temperature: float = 1.0,\n",
        "            eos_token: int = None,\n",
        "            padding_token: int = 0):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        if prompt is None:\n",
        "            start_tokens = [self.tokenizer.character_to_token(padding_token)]\n",
        "        else:\n",
        "            start_tokens = self.tokenizer.tokenize(prompt)\n",
        "\n",
        "        input_tensor = torch.tensor(\n",
        "            pad_left(\n",
        "                sequence=start_tokens,\n",
        "                final_length=self.model.max_sequence_length + 1,\n",
        "                padding_token=padding_token\n",
        "            ),\n",
        "            dtype=torch.long\n",
        "        ).to(get_device())\n",
        "\n",
        "        num_dims = len(input_tensor.shape)\n",
        "\n",
        "        if num_dims == 1:\n",
        "            input_tensor = input_tensor[None, :]\n",
        "\n",
        "        out = input_tensor\n",
        "        for _ in range(max_tokens_to_generate):\n",
        "\n",
        "            x = out[:, -self.model.max_sequence_length:]\n",
        "\n",
        "            mask = torch.ones_like(x)\n",
        "            mask[x == padding_token] = 0\n",
        "\n",
        "            # Compute the next token probabilities\n",
        "            next_token_probabilities = self.model.next_token_probabilities(\n",
        "                x=x,\n",
        "                temperature=temperature,\n",
        "                mask=mask\n",
        "            )\n",
        "\n",
        "            # Sample the next token from the probability distribution\n",
        "            next_token = torch.multinomial(next_token_probabilities, num_samples=1)\n",
        "\n",
        "            # Append the next token to the output\n",
        "            out = torch.cat([out, next_token], dim=1)\n",
        "\n",
        "            # If the end of sequence token is reached, stop generating tokens\n",
        "            if eos_token is not None and next_token == eos_token:\n",
        "                break\n",
        "\n",
        "        generated_tokens = out[0].tolist()\n",
        "        return ''.join([self.tokenizer.token_to_character(token) for token in generated_tokens])\n",
        "\n"
      ],
      "metadata": {
        "id": "i3V17rDluw3b"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_sequences(max_sequence_length, tokenized_training_data):\n",
        "    # Create sequences of length max_sequence_length + 1\n",
        "    # The last token of each sequence is the target token\n",
        "    sequences = []\n",
        "    for i in range(0, len(tokenized_training_data) - max_sequence_length - 1):\n",
        "        sequences.append(tokenized_training_data[i: i + max_sequence_length + 1])\n",
        "    return sequences\n",
        "\n",
        "\n",
        "def tokenize_and_pad_training_data(max_sequence_length, tokenizer, training_data):\n",
        "    # Tokenize the training data\n",
        "    tokenized_training_data = tokenizer.tokenize(training_data)\n",
        "    for _ in range(max_sequence_length):\n",
        "        # Prepend padding tokens\n",
        "        tokenized_training_data.insert(0, tokenizer.character_to_token('<pad>'))\n",
        "    return tokenized_training_data\n",
        "\n"
      ],
      "metadata": {
        "id": "R7bNi-w_uw52"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Runner(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def run(self):\n",
        "        # Create the tokenizer\n",
        "        tokenizer = Tokenizer()\n",
        "\n",
        "        embedding_dimension = 256\n",
        "        max_sequence_length = 20\n",
        "        number_of_tokens = tokenizer.size()\n",
        "\n",
        "        # Create the model\n",
        "        model = AutoregressiveWrapper(LanguageModel(\n",
        "            embedding_dimension=embedding_dimension,\n",
        "            number_of_tokens=number_of_tokens,\n",
        "            number_of_heads=4,\n",
        "            number_of_layers=3,\n",
        "            dropout_rate=0.1,\n",
        "            max_sequence_length=max_sequence_length\n",
        "        )).to(get_device())\n",
        "\n",
        "        # Create the training data\n",
        "        # training_data = '. '.join([\n",
        "        #     'cats rule the world',\n",
        "        #     'dogs are the best',\n",
        "        #     'elephants have long trunks',\n",
        "        #     'monkeys like bananas',\n",
        "        #     'pandas eat bamboo',\n",
        "        #     'tigers are dangerous',\n",
        "        #     'zebras have stripes',\n",
        "        #     'lions are the kings of the savannah',\n",
        "        #     'giraffes have long necks',\n",
        "        #     'hippos are big and scary',\n",
        "        #     'rhinos have horns',\n",
        "        #     'penguins live in the arctic',\n",
        "        #     'polar bears are white'\n",
        "        # ])\n",
        "\n",
        "        training_data = '. '.join([\n",
        "          'once upon a time, in a small village',\n",
        "          'there lived a young girl named lily',\n",
        "          'lily loved to explore the forest',\n",
        "          'one day, she found a hidden path',\n",
        "          'the path led to a secret garden',\n",
        "          'the garden was filled with beautiful flowers',\n",
        "          'lily picked a bright red rose',\n",
        "          'suddenly, a fairy appeared before her',\n",
        "          'the fairy thanked lily for visiting',\n",
        "          'she granted lily three wishes',\n",
        "          'lily was astonished and grateful',\n",
        "          'her first wish was for a friend',\n",
        "          'the fairy smiled and waved her wand',\n",
        "          'a small puppy appeared at lily’s feet',\n",
        "          'lily named the puppy max',\n",
        "          'max and lily became best friends',\n",
        "          'they played together every day',\n",
        "          'lily’s second wish was for adventure',\n",
        "          'the fairy granted her wish again',\n",
        "          'lily and max found a treasure map',\n",
        "          'they decided to follow the map',\n",
        "          'their journey led them to a distant land',\n",
        "          'they crossed rivers and climbed mountains',\n",
        "          'one day, they reached a dark cave',\n",
        "          'inside the cave, they found a treasure chest',\n",
        "          'the chest was filled with gold and jewels',\n",
        "          'lily and max were very happy',\n",
        "          'they decided to share the treasure',\n",
        "          'lily’s third wish was for happiness',\n",
        "          'the fairy granted her final wish',\n",
        "          'lily returned to her village',\n",
        "          'she used the treasure to help others',\n",
        "          'the village became prosperous',\n",
        "          'everyone thanked lily for her kindness',\n",
        "          'lily and max continued to explore',\n",
        "          'they discovered new places together',\n",
        "          'one day, they found a magical book',\n",
        "          'the book contained stories of old',\n",
        "          'lily read the book every night',\n",
        "          'she learned about different lands',\n",
        "          'max listened to her stories',\n",
        "          'they dreamed of new adventures',\n",
        "          'lily decided to write her own stories',\n",
        "          'she wrote about their adventures',\n",
        "          'her stories became very popular',\n",
        "          'people from far and wide came to hear them',\n",
        "          'lily was now a famous storyteller',\n",
        "          'she continued to explore with max',\n",
        "          'they traveled to new places',\n",
        "          'they met interesting people',\n",
        "          'they helped those in need',\n",
        "          'one day, they found a magic lamp',\n",
        "          'a genie appeared from the lamp',\n",
        "          'he offered lily three more wishes',\n",
        "          'lily was thoughtful and kind',\n",
        "          'her first wish was for peace',\n",
        "          'the genie granted her wish',\n",
        "          'her village was peaceful and happy',\n",
        "          'her second wish was for knowledge',\n",
        "          'the genie granted her wish',\n",
        "          'lily became very wise',\n",
        "          'she shared her knowledge with others',\n",
        "          'her third wish was for max',\n",
        "          'she wished for his happiness',\n",
        "          'the genie granted her wish',\n",
        "          'max was always happy and healthy',\n",
        "          'lily and max continued their adventures',\n",
        "          'they sailed across the ocean',\n",
        "          'they discovered hidden islands',\n",
        "          'they made new friends everywhere',\n",
        "          'lily wrote about their travels',\n",
        "          'her stories inspired many people',\n",
        "          'lily and max returned home',\n",
        "          'they were welcomed with open arms',\n",
        "          'their village was proud of them',\n",
        "          'lily’s stories were celebrated',\n",
        "          'max was loved by everyone',\n",
        "          'they lived happily ever after',\n",
        "          'the fairy visited them often',\n",
        "          'she was pleased with lily’s choices',\n",
        "          'lily thanked the fairy for everything',\n",
        "          'she knew she was blessed',\n",
        "          'max wagged his tail happily',\n",
        "          'they looked forward to new adventures',\n",
        "          'their story became a legend',\n",
        "          'people told it for generations',\n",
        "          'lily and max were remembered forever',\n",
        "          'they left a legacy of kindness and courage',\n",
        "          'their village remained a place of wonder',\n",
        "          'new explorers came to find their own paths',\n",
        "          'lily’s garden became a symbol of hope',\n",
        "          'the end of one adventure led to another',\n",
        "          'lily and max’s spirits lived on',\n",
        "          'in every story and every dream',\n",
        "          'they inspired others to seek their own journeys',\n",
        "          'and to always believe in the magic of wishes'\n",
        "      ])\n",
        "\n",
        "\n",
        "\n",
        "        tokenized_and_padded_training_data = tokenize_and_pad_training_data(max_sequence_length, tokenizer, training_data)\n",
        "        sequences = create_training_sequences(max_sequence_length, tokenized_and_padded_training_data)\n",
        "\n",
        "        # Train the model\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "        trainer = Trainer(model, tokenizer, optimizer)\n",
        "        loss_per_epoch = trainer.train(sequences, epochs=50, batch_size=16)\n",
        "\n",
        "        # Plot the loss per epoch in log scale\n",
        "        plt.plot(loss_per_epoch)\n",
        "        plt.yscale('log')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.show()\n",
        "\n",
        "        model.save_checkpoint('./trained_model')\n",
        "\n",
        "        # Generate text\n",
        "        max_tokens_to_generate = 400\n",
        "        generator = Generator(model, tokenizer)\n",
        "        generated_text = generator.generate(\n",
        "            max_tokens_to_generate=max_tokens_to_generate,\n",
        "            prompt=\"village\",\n",
        "            padding_token=tokenizer.character_to_token('<pad>')\n",
        "        )\n",
        "        print(generated_text.replace('<pad>', ''))\n",
        "\n"
      ],
      "metadata": {
        "id": "jm9uKC7Duw8V"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_left(sequence, final_length, padding_token):\n",
        "    return [padding_token] * (final_length - len(sequence)) + sequence"
      ],
      "metadata": {
        "id": "dB_HiNaJuw_t"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Runner().run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVc_-3qHuxnp",
        "outputId": "8471b2bc-8501-48e0-8ea8-145557d8ffd6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Loss: 2.0243724392583737\n",
            "Epoch: 1 Loss: 1.1062844258088331\n",
            "Epoch: 2 Loss: 0.29391960681487733\n",
            "Epoch: 3 Loss: 0.14753006724640727\n",
            "Epoch: 4 Loss: 0.11371550329316121\n",
            "Epoch: 5 Loss: 0.0985630507258555\n",
            "Epoch: 6 Loss: 0.0880384985715724\n",
            "Epoch: 7 Loss: 0.07939659198746085\n",
            "Epoch: 8 Loss: 0.07150583910361792\n",
            "Epoch: 9 Loss: 0.06495338177774101\n",
            "Epoch: 10 Loss: 0.05947613083005238\n",
            "Epoch: 11 Loss: 0.05329583157212115\n",
            "Epoch: 12 Loss: 0.04815720190974669\n",
            "Epoch: 13 Loss: 0.04241030430868985\n",
            "Epoch: 14 Loss: 0.03940461355243595\n",
            "Epoch: 15 Loss: 0.03331442148639606\n",
            "Epoch: 16 Loss: 0.029882346109773677\n",
            "Epoch: 17 Loss: 0.02760730530224884\n",
            "Epoch: 18 Loss: 0.022555430964880194\n",
            "Epoch: 19 Loss: 0.020439524607634388\n",
            "Epoch: 20 Loss: 0.017395241409898378\n",
            "Epoch: 21 Loss: 0.016430071938465025\n",
            "Epoch: 22 Loss: 0.014457075334995842\n",
            "Epoch: 23 Loss: 0.012841325369103847\n",
            "Epoch: 24 Loss: 0.011680084817971174\n",
            "Epoch: 25 Loss: 0.009251495211523993\n",
            "Epoch: 26 Loss: 0.00876915362193988\n",
            "Epoch: 27 Loss: 0.008009941388781253\n",
            "Epoch: 28 Loss: 0.009320407353208373\n",
            "Epoch: 29 Loss: 0.007863726674538786\n",
            "Epoch: 30 Loss: 0.00785946602585542\n",
            "Epoch: 31 Loss: 0.007227334860614904\n",
            "Epoch: 32 Loss: 0.006284669842688555\n",
            "Epoch: 33 Loss: 0.005859788927619565\n",
            "Epoch: 34 Loss: 0.0061776958798593394\n",
            "Epoch: 35 Loss: 0.0074965034355045645\n",
            "Epoch: 36 Loss: 0.006026994258018721\n",
            "Epoch: 37 Loss: 0.006222241826435493\n",
            "Epoch: 38 Loss: 0.005865434709536343\n",
            "Epoch: 39 Loss: 0.005500571391166886\n",
            "Epoch: 40 Loss: 0.00574736778197313\n",
            "Epoch: 41 Loss: 0.005783135272744962\n",
            "Epoch: 42 Loss: 0.006067376264721903\n",
            "Epoch: 43 Loss: 0.004451198763980266\n",
            "Epoch: 44 Loss: 0.004787429982955543\n",
            "Epoch: 45 Loss: 0.00646849643243723\n",
            "Epoch: 46 Loss: 0.0054318161100687015\n",
            "Epoch: 47 Loss: 0.00518678804024393\n",
            "Epoch: 48 Loss: 0.0034791519660145173\n",
            "Epoch: 49 Loss: 0.004082757017490972\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD/ElEQVR4nO3dd3RUdf7/8ddMekISEhJSIKG3UAJCEiIWkKyIigXXtS2i7ooguir63a/+dhXd1dXvqqwio4gNu4gKdqUovYcuvQdCEkIglbSZ+/sjEM0SkYRJ7pTn45w5h9x7ufOezwHmxf00i2EYhgAAALyQ1ewCAAAAzEIQAgAAXosgBAAAvBZBCAAAeC2CEAAA8FoEIQAA4LUIQgAAwGv5ml2AK3M4HMrOzlZoaKgsFovZ5QAAgLNgGIaKi4sVHx8vq/XMz3wIQmeQnZ2thIQEs8sAAACNkJWVpbZt257xGoLQGYSGhkqqaciwsDCTqwEAAGejqKhICQkJtd/jZ0IQOoNT3WFhYWEEIQAA3MzZDGthsDQAAPBaBCEAAOC1CEIAAMBrEYQAAIDXIggBAACvRRACAABeiyAEAAC8FkEIAAB4LYIQAADwWgQhAADgtQhCAADAaxGEAACA1yIImaS0olrrs46bXQYAAF6NIGSCvfml6vePubrltRWqrHaYXQ4AAF6LIGSCdpHBCgvyU2mlXWv2FZhdDgAAXosgVA+bzaakpCSlpKQ0yf2tVosGd4uWJC3YcaRJ3gMAAPw2glA9xo8fry1btmj16tVN9h6ngtCP2/Ka7D0AAMCZEYRMcmHnaPlYLdqZV6KsgjKzywEAwCsRhEwSHuyn/okRkugeAwDALAQhEw3ufnKcEN1jAACYgiBkoiHdWkuSlu7OV3mV3eRqAADwPgQhE3WPDVVsWKDKqxxauZdp9AAANDeCkIksFouGdGf2GAAAZiEImezirjXdYwsZMA0AQLMjCJlsUOdW8vOxaG9+qfbml5pdDgAAXoUgZLLQQD+ltI+UJC3YTvcYAADNiSDkAk7NHvtxO91jAAA0J4KQCzg1YHrFnqMqq6w2uRoAALwHQcgFdIpuobYRQaqsdmj57qNmlwMAgNcgCLkAi8Xyi+4xxgkBANBcCEIu4ufd6I/IMAyTqwEAwDsQhFxEeqdW8ve16tDxE9p9pMTscgAA8AoEIRcR7O+rgR1bSap5KgQAAJoeQciFDDnVPcY4IQAAmgVByIWcGjC9el+BisurTK4GAADPRxByIe2jQtQhKkRVdkNLdzGNHgCApkYQcjGnZo+x3QYAAE2PIORifrmeENPoAQBoWgQhF5PaIVJBfj7KLarQ1sPFZpcDAIBHIwi5mEA/H53f6eQ0errHAABoUgQhFzS4e0332EJ2owcAoEkRhFzQ4K41A6YzDxxTYRnT6AEAaCoEIReUEBmsLq1byO4wtHgXT4UAAGgqBCEXNeRk9xjbbQAA0HQIQi7q1HpCC3fkyeFgGj0AAE2BIOSiBrSLVIi/j/JLKrXlcJHZ5QAA4JE8Pgh99dVX6tatm7p06aLXX3/d7HLOmr+vVT3bhEuSdh8pMbkaAAA8k0cHoerqak2YMEE//PCD1q1bp2effVZHj7rPHl6JkcGSpKyCMpMrAQDAM3l0EFq1apV69uypNm3aqEWLFho+fLjmzJljdlln7VQQOkAQAgCgSbh0EFq0aJFGjBih+Ph4WSwWzZ49+7RrbDab2rdvr8DAQKWlpWnVqlW157Kzs9WmTZvan9u0aaNDhw41R+lOkRAZJEnKKjhhciUAAHgmlw5CpaWlSk5Ols1mq/f8jBkzNGHCBE2cOFFr165VcnKyhg0bpry8xm1NUVFRoaKiojovM/FECACApuXSQWj48OF68sknde2119Z7ftKkSbrzzjt1++23KykpSVOnTlVwcLDefPNNSVJ8fHydJ0CHDh1SfHz8r77f008/rfDw8NpXQkKCcz9QAyWcDEKHC0+oyu4wtRYAADyRSwehM6msrFRmZqYyMjJqj1mtVmVkZGj58uWSpNTUVG3evFmHDh1SSUmJvv32Ww0bNuxX7/nII4+osLCw9pWVldXkn+NMolsEKNDPKochZR+newwAAGfzNbuAxsrPz5fdbldMTEyd4zExMdq2bZskydfXV88//7yGDBkih8Ohv/71r2rVqtWv3jMgIEABAQFNWndDWCwWJUQEa2deiQ4UlKldqxCzSwIAwKO4bRA6W1dddZWuuuoqs8totMTIn4MQAABwLrftGouKipKPj49yc3PrHM/NzVVsbKxJVTlfQu1aQnSNAQDgbG4bhPz9/dW/f3/Nnz+/9pjD4dD8+fOVnp5uYmXOlcCiigAANBmX7horKSnRrl27an/eu3ev1q9fr8jISCUmJmrChAkaPXq0BgwYoNTUVL3wwgsqLS3V7bfffk7va7PZZLPZZLfbz/UjnDOm0AMA0HQshmG47NbmCxYs0JAhQ047Pnr0aE2fPl2SNGXKFD377LPKyclR3759NXnyZKWlpTnl/YuKihQeHq7CwkKFhYU55Z4NtS2nSJe9sFgtg/20/rFLTakBAAB30pDvb5cOQmZzhSBUWlGtnhO/lyRtmHipwoP8TKkDAAB30ZDvb7cdI+QtQgJ8FdXCXxLjhAAAcDaCkBtoG1EzTujgMYIQAADORBByAwyYBgCgaRCE6mGz2ZSUlKSUlBSzS5FEEAIAoKkQhOoxfvx4bdmyRatXrza7FElSQmSQJOkAiyoCAOBUBCE3cGpRxYM8EQIAwKkIQm7gVNfYwWMnZHew2gEAAM5CEHIDceFB8rVaVGl3KLeo3OxyAADwGAQhN+BjtahNRM04IdYSAgDAeQhCboKZYwAAOB9BqB6uNn1e+nlRRZ4IAQDgPASherja9Hnp5ydCWceYQg8AgLMQhNwEXWMAADgfQchN/LyoIkEIAABnIQi5iVNPhI4UV+hEpd3kagAA8AwEITcRHuSn0EBfSexCDwCAsxCE3ITFYlFCBOOEAABwJoKQG6mdOUYQAgDAKQhC9XDFdYQkKbHVqSdCTKEHAMAZCEL1cMV1hCQpIYKZYwAAOBNByI0k1O5CTxACAMAZCEJu5JeLKhqGYXI1AAC4P4KQG2kTESSLRSqrtOtoaaXZ5QAA4PYIQm4kwNdHsWGBkpg5BgCAMxCE3EwCe44BAOA0BCE3c2pRRZ4IAQBw7ghCbubnRRVZSwgAgHNFEHIzia1YSwgAAGchCNXDVVeWlsR+YwAAOBFBqB6uurK09HPX2OHCE6qyO0yuBgAA90YQcjPRoQEK8LXKYUjZxxknBADAuSAIuRmLxVJnhWkAANB4BCE3xFpCAAA4B0HIDTGFHgAA5yAIuaGESBZVBADAGQhCbighgrWEAABwBoKQG0psdfKJ0DGCEAAA54Ig5IZOLap4vKxKhSeqTK4GAAD3RRByQyEBvmoV4i+JcUIAAJwLgpCbOjVg+iDdYwAANBpBqB6uvNfYKSyqCADAuSMI1cOV9xo7JSGSmWMAAJwrgpCbYlFFAADOHUHITbGoIgAA544g5KZOTaE/eOyEHA7D5GoAAHBPBCE3FRceKF+rRZV2h3KLy80uBwAAt0QQclO+Pla1ObXVxlG6xwAAaAyCkBs71T3GzDEAABqHIOTGagdMH2PmGAAAjUEQcmOJzBwDAOCcEITcGIsqAgBwbghCbownQgAAnBuCkBs7FYTyiit0otJucjUAALgfgpAbCw/yU2iAryR2oQcAoDEIQm7MYrH8YuYYQQgAgIYiCNXDZrMpKSlJKSkpZpfym051j+05UmpyJQAAuB+CUD3Gjx+vLVu2aPXq1WaX8pt6tQmTJGXuP2ZyJQAAuB+CkJtL79RKkrRiz1E2XwUAoIEIQm6ud5uWCvLz0bGyKu3IKza7HAAA3ApByM35+1o1oH2EJGn57qMmVwMAgHshCHmAU91jBCEAABqGIOQB0jvWBKGVewsYJwQAQAMQhDxArzbhCvH3UeGJKm3NKTK7HAAA3AZByAP4+ViV0iFSEt1jAAA0BEHIQ5zqHluxhyAEAMDZIgh5iFMDplfuLZCdcUIAAJwVgpCHSIoLU2iAr4rLq7Ulm3FCAACcDYKQh/D1sSr11DihPfkmVwMAgHsgCHkQ1hMCAKBhCEIeZODJAdOr9x1Ttd1hcjUAALg+gpAH6REXprBAX5VUVGsz44QAAPhNBCEP4mO1KK0j3WMAAJwtgpCHObWe0HLWEwIA4DcRhDzMqXFCa/YVqIpxQgAAnBFByMN0jw1VRLCfyirt2niw0OxyAABwaQQhD2O1WpTWge02AAA4GwShethsNiUlJSklJcXsUhqF9YQAADg7BKF6jB8/Xlu2bNHq1avNLqVRascJ7S9QZTXjhAAA+DUEIQ/UNaaFWoX4q7zKoQ0Hj5tdDgAALosg5IEsFkvtUyG6xwAA+HUEIQ81kHFCAAD8JoKQh0rvWLMT/doDx1ReZTe5GgAAXBNByEN1im6h6NAAVVQ7tD7ruNnlAADgkghCHopxQgAA/DaCkAdj3zEAAM6MIOTBBp4cJ7T+wHHGCQEAUA+CkAfrEBWimLAAVdodWrv/mNnlAADgcghCHsxisdA9BgDAGRCEPNypfcfYgBUAgNMRhDzcqZlj67OO60Ql44QAAPglgpCHS4wMVnx4oKrshtbsLzC7HAAAXApByMNZLJba7TaW7Mw3uRoAAFwLQcgLXNK9tSTp7eX7tDe/1ORqAABwHQQhL3B5rzgN6txK5VUO/c/MDbI7DLNLAgDAJRCEvIDVatH/XddHIf4+WrP/mN5autfskgAAcAkEIS/RNiJYf7siSZL07PfbtedIickVAQBgPoKQF7kpNUEXdolSRbVDD9FFBgAAQcibWCwWPXNdH7UI8NXaA8f15hK6yAAA3o0g5GXatAzS36/oIUl6bs527cqjiwwA4L0IQl7ohpQEXdQ1WhXVDv3PJ3SRAQC8F0HIC1ksFj0zsrdCA3y17sBxvb54j9klAQBgCoKQl4pvGaRHr6yZRfb83B3alVdsckUAADQ/gpAXu35AWw3uFq3KaocenLlR1XaH2SUBANCsCEJerKaLrI9CA321Ieu4ptFFBgDwMgQhLxcbHqiJI3pKkl6Yu1M7cukiAwB4D4IQdN15bXRJ99aqtDt017uZrDoNAPAaBCHIYrHo6ZG9FR8eqL35pbrGtlSLdhwxuywAAJqcVwSha6+9VhEREfr9739vdikuKyYsULPvGaTzEluqqLxat721Sm8s2SvDYI0hAIDn8oogdN999+mdd94xuwyX1zo0UB+OGajf928rhyH986st+usnG1VRbTe7NAAAmoRXBKHBgwcrNDTU7DLcQoCvj579fR89emWSrBZpZuZB3TRthfKKy80uDQAApzM9CC1atEgjRoxQfHy8LBaLZs+efdo1NptN7du3V2BgoNLS0rRq1armL9SLWCwW/emCDpp+e6rCAms2aL16ylJtPlRodmkAADhVo4JQVlaWDh48WPvzqlWrdP/992vatGkNvldpaamSk5Nls9nqPT9jxgxNmDBBEydO1Nq1a5WcnKxhw4YpLy+v9pq+ffuqV69ep72ys7Mb/uFQ66Ku0Zo9fpA6RofocGG5fj91mb7cQJsCADyHxWjEaNgLL7xQY8aM0ahRo5STk6Nu3bqpZ8+e2rlzp+6991499thjjSvGYtGsWbN0zTXX1B5LS0tTSkqKpkyZIklyOBxKSEjQvffeq4cffvis771gwQJNmTJFn3zyya9eU1FRoYqKitqfi4qKlJCQoMLCQoWFhTX8A3mIovIq/eXDdVqwvWYm2bjBnfRARlf5+5r+QBEAgNMUFRUpPDz8rL6/G/VNtnnzZqWmpkqSPv74Y/Xq1UvLli3T+++/r+nTpzfmlvWqrKxUZmamMjIyao9ZrVZlZGRo+fLlTnufU55++mmFh4fXvhISEpz+Hu4oLNBPb4xO0V0XdZQkvbJgt0a8tETrs46bWxgAAOeoUUGoqqpKAQEBkqR58+bpqquukiR1795dhw8fdlpx+fn5stvtiomJqXM8JiZGOTk5Z32fjIwMXX/99frmm2/Utm3bXw1RjzzyiAoLC2tfWVlZ51S/J/GxWvTI5T308i3nqVWIv7bnFmvky0v15FdbVFZZbXZ5AAA0im9jflPPnj01depUXXHFFZo7d67++c9/SpKys7PVqlUrpxboDPPmzTur6wICAmoDHup3ee84pXdspX9+tUWfrTuk15fs1ZwtuXpmZG+d3znK7PIAAGiQRj0R+r//+z+9+uqrGjx4sG666SYlJydLkr744ovaLjNniIqKko+Pj3Jzc+scz83NVWxsrNPeBw0TEeKvSTf01Vu3pyg+PFAHCsp08+sr9fCnG1V4osrs8gAAOGuNCkKDBw9Wfn6+8vPz9eabb9YeHzNmjKZOneq04vz9/dW/f3/Nnz+/9pjD4dD8+fOVnp7utPdB4wzp1lpzJlysW9PbSZI+Wp2l301aqO9/OvtuSwAAzNSoIHTixAlVVFQoIiJCkrR//3698MIL2r59u1q3bt2ge5WUlGj9+vVav369JGnv3r1av369Dhw4IEmaMGGCXnvtNb399tvaunWrxo0bp9LSUt1+++2NKf2s2Gw2JSUlKSUlpcnew1O0CPDVP67upY/vSlfHqBDlFVfornczdff7mTpceMLs8gAAOKNGTZ+/9NJLNXLkSI0dO1bHjx9X9+7d5efnp/z8fE2aNEnjxo0763stWLBAQ4YMOe346NGja2egTZkyRc8++6xycnLUt29fTZ48WWlpaQ0tu8EaMv0OUnmVXZPn79Sri/bI7jAU7O+jey/pojsuaK8AXx+zywMAeImGfH83KghFRUVp4cKF6tmzp15//XW99NJLWrdunT799FM99thj2rp1a6OLdyUEocb5KbtQj33+kzL3H5MkdYwK0WMjkjS4W8OeFgIA0BhNvo5QWVlZ7d5dc+bM0ciRI2W1WjVw4EDt37+/MbeEB+kZH65PxqZr0h+SFdUiQHvyS3XbW6t15ztrlFVQZnZ5AADUalQQ6ty5s2bPnq2srCx9//33uvTSSyVJeXl5PDmBpJpVwkee11Y/PnSx/nxBB/laLZq7JVdDJy3UpLk7dKKSHe0BAOZrVBB67LHH9NBDD6l9+/ZKTU2tncE1Z84c9evXz6kFwr2FBvrp71cm6dv7LtSgzq1UWe3Q5Pk7lTFpob7bfFiN6JkFAMBpGjVGSJJycnJ0+PBhJScny2qtyVOrVq1SWFiYunfv7tQim5vNZpPNZpPdbteOHTsYI+QkhmHo2805evKrLcouLJckXdglSk9c1VMdo1uYXB0AwFM0+WDpXzq1C33btm3P5TYuicHSTaOsslov/7hb0xbtUaXdIT8fi8Zc1FHjh3RWsH+jFjsHAKBWkw+Wdjgc+sc//qHw8HC1a9dO7dq1U8uWLfXPf/5TDoejUUXDewT7++qhYd30/QMXaXC3aFXZDdl+3K2M5+kuAwA0r0b99/tvf/ub3njjDT3zzDMaNGiQJGnJkiV6/PHHVV5erqeeesqpRcIzdYgK0Vu3pWjOllz948stOnT8hMa+t1YXdY3W4yOS6C4DADS5RnWNxcfHa+rUqbW7zp/y+eef6+6779ahQ4ecVqCZ6BprPicq7Xp5wS69urCmu8zfx6o7L+pAdxkAoMGavGusoKCg3gHR3bt3V0FBQWNuCS8X5O+jBy+t6S67uGu0Ku2O2u6yrzZm010GAGgSjQpCycnJmjJlymnHp0yZoj59+pxzUfBeHaJCNP32FL06qr/atAxSdmG57vlgna59eZlW7yNkAwCcq1FdYwsXLtQVV1yhxMTE2jWEli9frqysLH3zzTe68MILnV5oc2L6vGs4UWnXq4tqZpeVnVyA8dKkGP3v8O7qxPghAMCvaJbp89nZ2bLZbNq2bZskqUePHhozZoyefPJJTZs2rTG3dDmMEXINeUXl+s+8nZqx+oAchuRjtejm1ETdl9FFUS0CzC4PAOBimnUdoV/asGGDzjvvPNntnrF9AkHItezMLdYz327T/G15kqQWAb4aN7iT7hjUQUH+7G4PAKjR5IOlATN0iQnVG7el6IM709S7TbhKKqr17PfbNeS5BZqx+oCq7KxhBQBoGIIQ3M75naL0+fhBevHGvmrTMkg5ReX63083aejzCzVzTZaqCUQAgLNEEIJbsloturpvG81/8GL9/YoeahXirwMFZfqfTzYqY9JCfbb2IIEIAPCbGjRGaOTIkWc8f/z4cS1cuJAxQmh2ZZXVemf5fk1btEcFpZWSpI5RIfrL0C4akRwvH6vF5AoBAM2lyQZL33777Wd13VtvvXW2t3RpBCH3U1pRrbeX79O0RXt0vKxKktQpOkT3ZXTVlb3jZCUQAYDHM23WmKchCLmv4vIqvb1sn15bvFeFJ2oCUffYUP1rZG+dlxhhcnUAgKZEEDpHLKjoOYrKq/TWkn16fckeFZdXy2KR/pjWTv9zWTeFBfqZXR4AoAkQhJyEJ0Keo6C0Uk99vVWfrj0oSYoJC9DjI3rqsl6xsljoLgMAT8I6QsB/iQzx1/N/SNYHf05Th6gQ5RZVaNz7a3XnO5nKPn7C7PIAACYhCMGrnN85St/ed6HuvaSz/Hwsmrc1V7+btFBvLtkru4OHowDgbQhC8DqBfj568NJu+uYvF2pAuwiVVtr1j6+26NqXl2rzoUKzywMANCOCELxWl5hQfXxXup66tpdCA3218WChrpqyRI/O3qxjJ9ciAgB4NoIQvJrVatEtae00/8GLdWWfODkM6d0V+zX4uQV6Z/k+VqcGAA/HrLEzYNaY91m++6ie+PInbcspliR1iwnVxBFJOr9zlMmVAQDOFtPnnYQg5J2q7Q59uDpLz8/ZXrs69WU9Y/W3K3ooITLY5OoAAL+F6fPnyGazKSkpSSkpKWaXAhP4+lg1amA7LXhosEant5OP1aLvfsrR0EkL9fyc7SqrrDa7RACAk/BE6Ax4IgRJ2p5TrCe+/EnLdh+VJMWGBeqZ63prcLfWJlcGAKgPT4QAJ+oWG6r3/5ymqX/sr7YRQcopKtdtb63WU19vUWU1g6kBwJ0RhICzYLFYdFmvWM2bcLFGp7eTJL22eK+ue2WZ9uaXmlwdAKCxCEJAAwT6+eiJq3tp2qj+ahnsp02HCnXl5MX67OQeZgAA90IQAhrh0p6x+va+C5XWIVKllXZN+HiDJsxYr5IKBlIDgDshCAGNFBcepA/uHKgJv+sqq0X6bN0hXTl5sTYdZJsOAHAXBCHgHPhYLfrL0C6acVe64sMDte9omUa+slSvL94jB5u4AoDLIwgBTpDSPlLf3HehLusZqyq7oSe/3qrhLy7W+yv3q5TuMgBwWawjdAasI4SGMgxDH6w6oKe+3qqySrskKTTQV9f3T9Co9HbqEBVicoUA4PnYYsNJCEJorMITVfok86DeXb5P+46W1R6/uGu0Rp/fThd3bS0fq8XECgHAcxGEnIQghHPlcBhatPOI3lm+Xz9uz9Opv22JkcH648BE3ZCSqPAgP3OLBAAPQxA6RzabTTabTXa7XTt27CAIwSn2Hy3Veyv2a8bqLBWV14wbahsRpA/+PFCJrdjMFQCchSDkJDwRQlM4UWnXFxsO6aUfdungsROKDQvU+3emqVN0C7NLAwCPwF5jgAsL8vfRDSmJ+mzc+erSuoVyisp1w6srtD2n2OzSAMDrEIQAk7QOC9RHYwYqKS5M+SUVunHacm0+xGKMANCcCEKAiVq1CNCHdw5UckJLHSur0k2vrdDaA8fMLgsAvAZBCDBZeLCf3vtTqlLbR6q4vFqjXl+pFXuOml0WAHgFghDgAkID/TT9jhRd0DlKpZV23fbWKi3accTssgDA4xGEABcR7O+r10cP0CXdW6u8yqE/v71G87bkml0WAHg0ghDgQgL9fDT1j/01vFesKu0OjX0vU19uyDa7LADwWAQhwMX4+1r10k39dHXfeFU7DN374TpNmLFeR0sqzC4NADwOQQhwQb4+Vk36Q1/9+YIOslikz9Yd0tBJCzVj9QE5HKyBCgDOQhACXJSP1aK/X5mkWXcPUo+4MB0vq9L/frpJN05boZ25LL4IAM5AEAJcXN+ElvrynkH62+U9FOTno1X7CnT55MV67vvtKq+ym10eALg1ghDgBnx9rLrzoo6aO+EiZfRorSq7oSk/7tKwFxZp8U6m2QNAYxGEADfSNiJYr906QFP/2F+xYYHaf7RMo95YpXs/XKddeSVmlwcAbofd5+ths9lks9lkt9u1Y8cOdp+HSyour9Lzc3boneX7dGr8dEaP1rrzwo5K7RApi8ViboEAYJKG7D5PEDqDhjQkYJbNhwo1ef5Ozd2aq1N/m5PbhmvMRZ00rGeMfH148AvAuxCEnIQgBHey50iJXl+yV59mHlRFtUOSlBAZpD8N6qDrByQoJMDX5AoBoHkQhJyEIAR3lF9SoXeX79c7y/fpWFmVJCk8yE9/HJio8UM6K9ifQATAsxGEnIQgBHd2otKuT9Ye1BuL92jf0TJJ0kVdo/XG6AHyo7sMgAdryPc3/xoCHirI30ejBrbT/AcHy3bzeQr0s2rRjiOa+MVP4v8/AFCDIAR4OB+rRVf0idPkG/vJYpE+WHlA0xbtMbssAHAJBCHAS1zaM1Z/vyJJkvT0t9v0zabDJlcEAOYjCAFe5I5B7TU6vZ0k6YEZ67X2wDGTKwIAcxGEAC9isVj02IieGtq9tSqqHbrz7TU6cHIgNQB4I4IQ4GV8rBZNvqmfesaH6WhppW6fvkqFJ6fZA4C3IQgBXigkwFdv3pai+PBA7T5SqrveW6PKk4swAoA3IQgBXiomLFBv3p6iFgG+WrGnQA9/upFp9QC8DkEI8GLdY8P08i3nycdq0WfrDmny/F1mlwQAzYogBHi5i7pG68lrekmS/jNvh2w/7qKbDIDXIAgB0E2piRp7cSdJ0rPfb9el/1mo7zbn0FUGwOMRhABIkv73sm7693V9FB0aoH1HyzT2vUzdOG2FNh8qNLs0AGgybLp6Bmy6Cm9UUlGtqQt267XFe1RR7ZDFIl13Xlv9z7BuigkLNLs8APhN7D7vJAQheLNDx0/o399t0+frsyVJQX4+GntxJ425qKOC/H1Mrg4Afh1ByEkIQoC07sAx/fOrLVp74LgkKTYsUI9f1VOX9Yo1tzAA+BUN+f5mjBCAM+qXGKFPx52vl27qpzYtg5RTVK6x72Vq+tK9ZpcGAOeMIATgN1ksFo1Ijtf8By/WrSc3bX38yy16Yd4OZpYBcGsEoXrYbDYlJSUpJSXF7FIAlxLo56MnruqpBzK6SpJemLdTj3/xkxwOwhAA98QYoTNgjBDw695etk8Tv/hJknRN33g9e32y/Hz4vxUA8zFGCECTG31+e714Y1/5Wi2avT5bd72bqROVdrPLAoAGIQgBaLSr+7bRa7cOUKCfVT9sy9Otb65U4Ykqs8sCgLNGEAJwToZ0b613/5Sm0EBfrd53TDdOW6G84nKzywKAs0IQAnDOUtpHasaYdEW1CNDWw0W6fupyZRWUmV0WAPwmghAAp0iKD9MnY9PVNiJI+4+WafiLi3X/R+v0/U85Kq9i7BAA18SssTNg1hjQcLlF5bpj+mr9lF1UeyzY30dDurfW5b3iNKR7tIL9fU2sEICnY4sNJyEIAY3jcBhal3Vc320+rG825ejQ8RO15wL9rBrctbWG947VJd1bKzTQz8RKAXgigpCTEISAc2cYhjYdKtQ3m3L07ebD2n/057FDwf4+mjgiSX8YkCCLxWJilQA8CUHISQhCgHMZhqGth4v17ebD+nrjYe3JL5UkjUiO11PX9lIYT4cAOAFByEkIQkDTcTgMvbpoj56bs112h6HEyGC9dFM/JSe0NLs0AG6OlaUBuDyr1aJxgzvp47vS1aZlkA4UlOm6V5Zp2qLd7F0GoNkQhACYqn+7CH1z34W6vHesqh2G/vXNNt0+fbXySyrMLg2AFyAIATBdeJCfbDefp39d21sBvlYt3HFEw19crKW78s0uDYCHIwgBcAkWi0U3pyXqi3suUJfWLXSkuEJ/fGOlnvt+u6rtDrPLA+ChCEIAXEq32FB9cc8Fuik1QYYhTflxl657ZZl25RWbXRoAD0QQAuBygvx99PTIPppycz+FBfpqw8FCXT55iV5fvEd2BlIDcCKCEACXdWWfeM154GIN7hatymqHnvx6q26atkL7j5aaXRoAD0EQAuDSYsMD9dZtKXpmZG+F+Pto1b4CDX9xsd5bsV8sgwbgXBGEALg8i8WiG1MT9d39F2lgx0iVVdr199mbdeubq5T9i33MAKChCEIA3EZCZLA++PNAPXZlkgJ8rVq8M1/DXlikTzMP8nQIQKMQhAC4FavVojsu6KBv7rtQfRNaqri8Wg/O3KBRb6zS5kOFZpcHwM0QhAC4pU7RLfTJ2HT99bJu8vexasmufF350hLd99E6ZRWU/fYNAEBsunpGbLoKuIesgjI9N2e7Pl+fLUny97FqVHo73TOksyJC/E2uDkBzY/d5JyEIAe5l86FCPfPtNi05uTVHaICvxg7upDsGdVCQv4/J1QFoLgQhJyEIAe5p0Y4jevrbbdp6uEiSFBsWqAm/66rr+reVj9VicnUAmhpByEkIQoD7cjgMfb7hkJ77focOnZxif36nVnr7jlT5+TA8EvBkDfn+5l8DAB7JarXo2n5tNf/Bi/W3y3soxN9Hy3Yf1fNzdphdGgAXQhAC4NEC/Xx050Ud9dz1yZKkqQt368dteSZXBcBVEIQAeIXhveM0Or2dJGnCx+t1uJAVqQF4QRDKysrS4MGDlZSUpD59+mjmzJlmlwTAJP/vih7q1SZMx8qq9JcP16na7jC7JAAm8/gg5OvrqxdeeEFbtmzRnDlzdP/996u0lJ2rAW8U4Osj283nKTTAV6v3HdOkuYwXArydxwehuLg49e3bV5IUGxurqKgoFRQUmFsUANO0axWiZ67rI0l6ecFuLdxxxOSKAJjJ9CC0aNEijRgxQvHx8bJYLJo9e/Zp19hsNrVv316BgYFKS0vTqlWrGvVemZmZstvtSkhIOMeqAbizK/rEadTAmvFCD8xYr5zCcpMrAmAW04NQaWmpkpOTZbPZ6j0/Y8YMTZgwQRMnTtTatWuVnJysYcOGKS/v51kfffv2Va9evU57ZWdn115TUFCgW2+9VdOmTfvVWioqKlRUVFTnBcAz/e2KHkqKC1NBaaX+8hHjhQBv5VILKlosFs2aNUvXXHNN7bG0tDSlpKRoypQpkiSHw6GEhATde++9evjhh8/qvhUVFfrd736nO++8U6NGjfrV6x5//HE98cQTpx1nQUXAM+3NL9WVkxertNKue4Z01kPDupldEgAn8JgFFSsrK5WZmamMjIzaY1arVRkZGVq+fPlZ3cMwDN1222265JJLzhiCJOmRRx5RYWFh7SsrK+uc6gfg2jpEhejpk+OFbAt2aRHjhQCv49JBKD8/X3a7XTExMXWOx8TEKCcn56zusXTpUs2YMUOzZ89W37591bdvX23atKneawMCAhQWFlbnBcCzXZUcr5vTEmUYNeOFcouab7xQWWV1s70XgPr5ml1AU7vgggvkcND3D+DXPXZlktYdOK6th4v057fX6M6LOmpwt2iFBfo1yfsZhqHXFu/Rv7/briHdW+ulm/op0M+nSd4LwJm59BOhqKgo+fj4KDc3t87x3NxcxcbGmlQVAE8T6Ocj2839FOLvo02HCvWXD9fpvH/M1R9fX6m3l+2r3bTVGartDj36+Wb965ttqnYYmrslV3e+s0YnKu1Oew8AZ8+lg5C/v7/69++v+fPn1x5zOByaP3++0tPTTawMgKfpGN1CX957gcYN7qTOrVuo2mFoya58TfziJw165gdd/uJi/WfuDm0+VKjGzjEprajWmHcz9d6KA7JYpNvOb69gfx8t3pmv26evUmkFXWVAczN91lhJSYl27dolSerXr58mTZqkIUOGKDIyUomJiZoxY4ZGjx6tV199VampqXrhhRf08ccfa9u2baeNHXIWm80mm80mu92uHTt2MGsM8EJ780s1b0uu5m7J1Zr9BXL84l/KthFBGje4k/4wIEF+Pmf3/8nconLdMX21fsouUoCvVS/e2FeX9YrTmn0Fuu2t1SqpqFZK+wi9eVuKQpuoSw7wFg2ZNWZ6EFqwYIGGDBly2vHRo0dr+vTpkqQpU6bo2WefVU5Ojvr27avJkycrLS2tyWtrSEMC8FwFpZX6YVue5m7J0aId+TpRVdONlRgZrPszuujqvm3kY7X86u/fnlOs299apezCcrUK8dfroweoX2JE7fn1Wcc16o2VKi6vVt+Elnr7jlSFBxGGgMZyqyDkyghCAP5beZVdH606oCk/7lZ+SYUkqXPrFprwu666rGesrP8ViJbuytfYdzNVXFGtjtEhmn5bqhJbBZ92382HCvXHN1bqeFmVercJ17t/SlXLYP9m+UyApyEIOQlBCMCvKaus1tvL9mvqwt0qPFElSerVJkwPXtpNg7tGy2KxaOaaLD3y2SZVOwyldojUtFH9zxhuth4u0i2vr1RBaaV6xIXpvT+lqlWLgOb6SIDHIAg5CUEIwG8pKq/S64v36o3Fe1R6cubXgHYR6tUmXNOX7ZNUs1bRs9f3UYDvb0+R35FbrJtfW6n8kgp1jWmh9/6cptahgU35EQCPQxByEoIQgLNVUFqpqQt36+1l+1RR/fPaZfcM6awJv+t6WpfZmew+UqKbX1uh3KIKdYwO0Ys39FOQv48sFunUXSwWiyzSyWMWtWrhr5AAj18aDjgrBKFzxKwxAI2VW1SuKT/s0g/b8vSXoZ11Q0pio+6z/2ipbn5t5VmvYRToZ9XNqe005qKOig3nCRK8G0HISXgiBMBMWQVlemDGeu06UiLDqFmR2pCkk/9qG6o55jBUO5PN38eq6/q31biLO9U7KBvwBgQhJyEIAXAHhmFo8c58Tflxl1btLZAk+Vgtuio5XncP7qQuMaEmV1i/Lzdk60hxhW47v32Dug6B30IQchKCEAB3s3pfgab8sEsLdxyRVDOGaFhSrO65pLN6tQk3ubqfvbdiv/4+e7Mk6YGMrrovo4vJFcGTEISchCAEwF1tOlgo24+79N1PObXHhnSL1r9G9lZceJCJlUnfbc7R3e9n1lmt+43RAzS0R9PsFgDvQxByEoIQAHe3M7dYLy/YrS82ZMvuMBTVwl8v39JfqR0iTaln5Z6jGvXmKlVWO3RTaqJ8rRa9u2K/QgN8NfueQeoU3cKUuuBZGvL97dKbrgIAzk2XmFD954a+mvvAReoRF6b8kkrd/NoKvbt8X6M3j22sbTlF+vM7a1RZ7dClSTF68ppeevTKJKW0j1BxRbXGvLNGxeVVzVoTQBCqh81mU1JSklJSUswuBQCcomN0C3027nyNSI5XtcPQo5//pP/9dKPKT842a2qHjp/QbW+uVnF5zeayk2/qJx+rRf6+VtluOU+xYYHafaRUD368QQ4HHRVoPnSNnQFdYwA8jWEYem3xHj3z7TY5DCk5oaVe/WP/Jl176FhppX4/dZl2HylV15gWmnnX+QoPrrup7LoDx3TDqytUaXdowu+66i9DGTyNxqNrDABQL4vFojEXdard4X5D1nFd+dISrdlX0CTvd6LSrjveXq3dR0oVFx6o6bennhaCJKlfYoSevKaXJOk/83Zo/tbcJqkH+G8EIQDwQhd2idaX91yg7rGhyi+p0E2vrdB7K/Y7ddxQtd2hez5Yq3UHjis8yE/v3JGq+Ja/PmPtDykJ+uPARBmGdP9H67XnSInTaoE0ae4O3fPBWh0rrTS7FJdCEAIAL5XYKlif3X2+rugTpyq7ob/P3qxHPtukkorqc763YRj6f7M2af62PAX4WvXG6AFntbDjY1f21IB2JwdPv5vplFogLdiep8nzd+qrjYd18+srCUO/wBihM2CMEABvYBiGpi7co39/v02GIYX4++iqvm10c2qierdt+CKMx8sqNeWHXXp9yV5ZLdKrowbod0lnv0ZQXnG5Rry0RLlFFRrWM0av3NL/tJWn84rLtfVwsbYeLtK2w0XKPl6ulA4RurJPvLrHhspiYaXqU6rsDl32wiLtPlIqi0UyDKlHXJg++HOaIkL8zS6vSbCOkJMQhAB4k0U7jujxL3/SniOltcd6twnXzWmJuio5/oy72+/NL9W8LbmatzVXa/Yfk/3kzK9nRvbWjakN33h27YFjuvHk4Om7Lu6objGhNaEnpyb85Jf8+hONTtEhuqJPvEb0iXPZ7UWq7A6tO3BcO3KLdXXfeIUGnj5uylneWLJX//xqi1qF+Ou10QM05p1M5ZdUKCkuTO97aBgiCDkJQQiAtzEMQyv3FuiDlQf03eYcVdodkqQWAb66um+8bkpNVK824bI7DK09cEzztuRq7tbcOuFJkrrFhOqOC9rrhpSGh6BTPlp1QA9/tqnec1aL1D4qRD3iwpQUF6aoFv6avzVPC3YcUWW1o04dV/SJ05V94tTR5MUa9x8t1aIdR7RoZ76W7z5a2+13ZZ84Tbn5vCZ5z6MlFRr83AIVl1fXhtJdecW6cdpKjw5DBKFzZLPZZLPZZLfbtWPHDoIQAK9UUFqpTzMP6sNVB7Qn/+eg0z02VLlF5TpW9vPih75WiwZ2bKWhPVoro0eMEiKDnVLD099u1aeZB9UxqoV6xIWqR1yYesSFqWtMqIL8fU67vri8SvO25uqrDYe1aOcRVdl//opLigvT1X3jdU2/NooJa7rlAn5Zy7LdR7V45xEt2pGvAwVldc5HhvjrWFmlDEP6dNz56t8uwuk1/L9Zm/TBygPqGR+mL+65QD4nuxh35hbrptdqwlDP+Jow1DLYc8IQQchJeCIEADVPiZbvOaoPVh7Q9z/l1IaL8CA/DekWrYykGF3UNVphTdi90xiFZVWasyVHX208rKW78lV9srvOapEu6BKt685ro0uTYusNVPUpr7JrfdZxrdhzVAcKylRR5VB5lV3l1XadqLSrvMqh8mp77fHjJ6pquwilmrDYv12ELuoarYu6RKtnfJge+WyTZqzJUr/Elvps3PlOHdv0U3ahrnxpiQxD+viu9NO2VfHkMEQQchKCEADUlV9SoQXbj6htRJAGtIuQr497TD4+Vlqpbzfn6LO1B7Vm/7Ha4yH+Prq8d5xGntdWaR0i6wzKrqi2a0NWoZbvPqoVe44q88CxOt1uZ6NjVIgu7BKlC7tEa2CnVmrxX+Os8orKNfi5BSqrtGvyTf10VXL8uX3QkwzD0A3TVmjV3gKNSI7XSzf1q/e6mjC0QvkllR4VhghCTkIQAgDPs/9oqT5be0ifrTuorIITtcfbtAzSyPPayN/HqhV7jypz/zGVV9UNPlEtApTeqZV6xIUqxN9XgX5WBfr5KMDXp/bXNS+rIoL9z6oL7qX5O/X83B1q0zJI8x+8WIF+Z/eE6ky+3nhY4z9Yq0A/q+Y/OFhtzrB+kyeGIYKQkxCEAMBzGYah1fuO6bO1B/X1xsMqrmfNoqgW/krr2EoDO7ZSesdW6hQd4vSp+Scq7brk+QU6XFiuv17WTXcP7nzO98uYtFCHjp/Q/RlddH9G19/8Pb8MQz3iwjT24o5K79RKrUObfixVUyAIOQlBCAC8Q3mVXXO35OrrjYdltao2+HRu3aJZ1iSate6gHpixQS0CfPXjQ4MVHRrQ6Hu9OG+n/jOv5gnTvAkXn/UYqB25xbr5ZBg6pVtMqAZ1jtIFXVoptcPpXXuuiiDkJAQhAEBzcDgMXfPyUm08WKib0xL1r2t7N+o+2cdP6JLnF6i8yqEpN/fTlX0aNuYoq6BM763Yr6W78/VTdpF+mRB8rRb1TWipQZ2jdFHX6CaZ5eYsBCEnIQgBAJrLqr0F+sOry2W1SN/ed5G6xTZ8Mci/fLhOX2zIVmqHSM0YM/CcnmYVlFZq+e6jWrIrX8t252v/0brT/yeOSNLtgzo0+v5Nid3nAQBwM6kdIjW8V6wchvTUN1sb/PtX7yvQFxuyZbHUhJRz7dKLDPHXFX3i9PTI3lr4P0O0+K9D9MzI3hravbUkyfbjblVU28/pPVwBQQgAABfx8PDu8vOxaNGOI1qwPe+sf5/dYejxL36SJN2Ykqie8Q3fI+63JEQG68bURE0d1V+xYYHKL6nQVxsOO/19mhtBqB42m01JSUlKSUkxuxQAgBdp1ypEt53fXpL01NdbVW0/u3WLPsnM0k/ZRQoN9NVDl/72LLFz4edj1a3nt5Mkvbl0r9x9hA1BqB7jx4/Xli1btHr1arNLAQB4mXsu6aKIYD/tzCvRh6uzznjt0ZIKvbxgl576uqYr7f6MrmrVovEzzs7WTSmJCvSz6qfsIq3aW9Dk79eUCEIAALiQ8CC/2rV//jN3h4rKq+qcN4yaDW8fmLFe6U//oH9/t11F5dXq3SZct6a3a5YaI0L8dW2/tpJqngq5M4IQAAAu5ua0RHWKDlFBaaVsP+6SVLPW0cerszRiyhKNfHmZZq07pEq7Q8ltw/Xc9cmaOTZdfs245ckdg9pLkuZuyVXWf20o607cY2UkAAC8iJ+PVX+7oofumL5Gby3Zp4oqh2atO6TCEzVPh/x9rRrRJ163prdTckJLU2rsEhOqC7tEafHOfL29bJ/+fmWSKXWcK4IQAAAuaEi31rqgc5SW7MrX9GX7JEltI4L0x4Ht9IcBCYoMMX8/sDsu6KDFO/M1Y3WW7v9dV7dZefqX3K9iAAC8gMVi0eNXJemudzPVNiJYt6a30+BureVjbfotP87WxV2i1TE6RHuOlOqTNVm6zUUXWDwTxggBAOCiOrcO1fwHB+vtO1I1tEeMS4UgSbJaLbr95HT/6cv2yeFwv6n0BCEAANBoI89rq7BAX+07WqYfG7AIpKsgCAEAgEYLCfDVTamJkho2ld7hMPTPr7bozSXmTr8nCAEAgHNy6/nt5WO1aOmuo9qWU/Sb11fZHXpo5ga9sWSvnvx6i3YfKWmGKutHEAIAAOekTcsgDesZI0l6a8m+M157otKuu97N1GfrDsnHatFz1yerU3SLZqiyfgSherDXGAAADXPHyRljs9Yf0tGSinqvKSyr0qg3VuqHbXkK9LPqtVv7a+R5bZuzzNMQhOrBXmMAADRM/3YR6tM2XJXVDn246sBp53OLynXDtOVas/+YwgJ99d6f0nRJ9xgTKq2LIAQAAM6ZxWKpfSr0zvL9qqx21J7bm1+q615Zpm05xWodGqCPx6ZrQPtIs0qtgyAEAACc4vLecWodGqC84gp9s+mwJGnzoUJdP3WZDh47ofatgvXpuPPVPTbM5Ep/RhACAABO4e9r1aiB7STVTKVfvvuobpy2QvklleoZH6aZY89XQmSwyVXWRRACAABOc3Naovx9rdp4sFCj3lipkopqpXWI1IdjBio6NMDs8k5DEAIAAE7TqkWAru3bRpJU7TB0aVKM3r4jVWGBfiZXVj82XQUAAE41bnAnLd9zVEO6RevRK5Pk6+O6z10IQgAAwKnaR4Vo0V+HmF3GWXHdiAYAANDECEIAAMBrEYQAAIDXIggBAACvRRACAABeiyAEAAC8FkGoHjabTUlJSUpJSTG7FAAA0IQshmEYZhfhqoqKihQeHq7CwkKFhbnOBnEAAODXNeT7mydCAADAaxGEAACA1yIIAQAAr0UQAgAAXosgBAAAvBZBCAAAeC1fswtwZadWFigqKjK5EgAAcLZOfW+fzQpBBKEzKC4uliQlJCSYXAkAAGio4uJihYeHn/EaFlQ8A4fDoezsbIWGhspisTj13kVFRUpISFBWVhaLNTYD2rt50d7Ni/ZuXrR382pMexuGoeLiYsXHx8tqPfMoIJ4InYHValXbtm2b9D3CwsL4i9SMaO/mRXs3L9q7edHezauh7f1bT4JOYbA0AADwWgQhAADgtQhCJgkICNDEiRMVEBBgdilegfZuXrR386K9mxft3byaur0ZLA0AALwWT4QAAIDXIggBAACvRRACAABeiyAEAAC8FkHIJDabTe3bt1dgYKDS0tK0atUqs0vyCIsWLdKIESMUHx8vi8Wi2bNn1zlvGIYee+wxxcXFKSgoSBkZGdq5c6c5xbq5p59+WikpKQoNDVXr1q11zTXXaPv27XWuKS8v1/jx49WqVSu1aNFC1113nXJzc02q2L298sor6tOnT+2icunp6fr2229rz9PWTeuZZ56RxWLR/fffX3uMNneexx9/XBaLpc6re/futeebsq0JQiaYMWOGJkyYoIkTJ2rt2rVKTk7WsGHDlJeXZ3Zpbq+0tFTJycmy2Wz1nv/3v/+tyZMna+rUqVq5cqVCQkI0bNgwlZeXN3Ol7m/hwoUaP368VqxYoblz56qqqkqXXnqpSktLa6954IEH9OWXX2rmzJlauHChsrOzNXLkSBOrdl9t27bVM888o8zMTK1Zs0aXXHKJrr76av3000+SaOumtHr1ar366qvq06dPneO0uXP17NlThw8frn0tWbKk9lyTtrWBZpeammqMHz++9me73W7Ex8cbTz/9tIlVeR5JxqxZs2p/djgcRmxsrPHss8/WHjt+/LgREBBgfPjhhyZU6Fny8vIMScbChQsNw6hpWz8/P2PmzJm112zdutWQZCxfvtysMj1KRESE8frrr9PWTai4uNjo0qWLMXfuXOPiiy827rvvPsMw+PPtbBMnTjSSk5PrPdfUbc0ToWZWWVmpzMxMZWRk1B6zWq3KyMjQ8uXLTazM8+3du1c5OTl12j48PFxpaWm0vRMUFhZKkiIjIyVJmZmZqqqqqtPe3bt3V2JiIu19jux2uz766COVlpYqPT2dtm5C48eP1xVXXFGnbSX+fDeFnTt3Kj4+Xh07dtQtt9yiAwcOSGr6tmbT1WaWn58vu92umJiYOsdjYmK0bds2k6ryDjk5OZJUb9ufOofGcTgcuv/++zVo0CD16tVLUk17+/v7q2XLlnWupb0bb9OmTUpPT1d5eblatGihWbNmKSkpSevXr6etm8BHH32ktWvXavXq1aed48+3c6WlpWn69Onq1q2bDh8+rCeeeEIXXnihNm/e3ORtTRACcM7Gjx+vzZs31+nTh/N169ZN69evV2FhoT755BONHj1aCxcuNLssj5SVlaX77rtPc+fOVWBgoNnleLzhw4fX/rpPnz5KS0tTu3bt9PHHHysoKKhJ35uusWYWFRUlHx+f00a75+bmKjY21qSqvMOp9qXtneuee+7RV199pR9//FFt27atPR4bG6vKykodP368zvW0d+P5+/urc+fO6t+/v55++mklJyfrxRdfpK2bQGZmpvLy8nTeeefJ19dXvr6+WrhwoSZPnixfX1/FxMTQ5k2oZcuW6tq1q3bt2tXkf74JQs3M399f/fv31/z582uPORwOzZ8/X+np6SZW5vk6dOig2NjYOm1fVFSklStX0vaNYBiG7rnnHs2aNUs//PCDOnToUOd8//795efnV6e9t2/frgMHDtDeTuJwOFRRUUFbN4GhQ4dq06ZNWr9+fe1rwIABuuWWW2p/TZs3nZKSEu3evVtxcXFN/+f7nIdbo8E++ugjIyAgwJg+fbqxZcsWY8yYMUbLli2NnJwcs0tze8XFxca6deuMdevWGZKMSZMmGevWrTP2799vGIZhPPPMM0bLli2Nzz//3Ni4caNx9dVXGx06dDBOnDhhcuXuZ9y4cUZ4eLixYMEC4/Dhw7WvsrKy2mvGjh1rJCYmGj/88IOxZs0aIz093UhPTzexavf18MMPGwsXLjT27t1rbNy40Xj44YcNi8VizJkzxzAM2ro5/HLWmGHQ5s704IMPGgsWLDD27t1rLF261MjIyDCioqKMvLw8wzCatq0JQiZ56aWXjMTERMPf399ITU01VqxYYXZJHuHHH380JJ32Gj16tGEYNVPoH330USMmJsYICAgwhg4damzfvt3cot1Ufe0syXjrrbdqrzlx4oRx9913GxEREUZwcLBx7bXXGocPHzavaDd2xx13GO3atTP8/f2N6OhoY+jQobUhyDBo6+bw30GINneeG264wYiLizP8/f2NNm3aGDfccIOxa9eu2vNN2dYWwzCMc3+uBAAA4H4YIwQAALwWQQgAAHgtghAAAPBaBCEAAOC1CEIAAMBrEYQAAIDXIggBAACvRRACAABeiyAEAA1ksVg0e/Zss8sA4AQEIQBu5bbbbpPFYjntddlll5ldGgA35Gt2AQDQUJdddpneeuutOscCAgJMqgaAO+OJEAC3ExAQoNjY2DqviIgISTXdVq+88oqGDx+uoKAgdezYUZ988kmd379p0yZdcsklCgoKUqtWrTRmzBiVlJTUuebNN99Uz549FRAQoLi4ON1zzz11zufn5+vaa69VcHCwunTpoi+++KJpPzSAJkEQAuBxHn30UV133XXasGGDbrnlFt14443aunWrJKm0tFTDhg1TRESEVq9erZkzZ2revHl1gs4rr7yi8ePHa8yYMdq0aZO++OILde7cuc57PPHEE/rDH/6gjRs36vLLL9ctt9yigoKCZv2cAJzAKXvYA0AzGT16tOHj42OEhITUeT311FOGYRiGJGPs2LF1fk9aWpoxbtw4wzAMY9q0aUZERIRRUlJSe/7rr782rFarkZOTYxiGYcTHxxt/+9vffrUGScbf//732p9LSkoMSca3337rtM8JoHkwRgiA2xkyZIheeeWVOsciIyNrf52enl7nXHp6utavXy9J2rp1q5KTkxUSElJ7ftCgQXI4HNq+fbssFouys7M1dOjQM9bQp0+f2l+HhIQoLCxMeXl5jf1IAExCEALgdkJCQk7rqnKWoKCgs7rOz8+vzs8Wi0UOh6MpSgLQhBgjBMDjrFix4rSfe/ToIUnq0aOHNmzYoNLS0trzS5culdVqVbdu3RQaGqr27dtr/vz5zVozAHPwRAiA26moqFBOTk6dY76+voqKipIkzZw5UwMGDNAFF1yg999/X6tWrdIbb7whSbrllls0ceJEjR49Wo8//riOHDmie++9V6NGjVJMTIwk6fHHH9fYsWPVunVrDR8+XMXFxVq6dKnuvffe5v2gAJocQQiA2/nuu+8UFxdX51i3bt20bds2STUzuj766CPdfffdiouL04cffqikpCRJUnBwsL7//nvdd999SklJUXBwsK677jpNmjSp9l6jR49WeXm5/vOf/+ihhx5SVFSUfv/73zffBwTQbCyGYRhmFwEAzmKxWDRr1ixdc801ZpcCwA0wRggAAHgtghAAAPBajBEC4FHo7QfQEDwRAgAAXosgBAAAvBZBCAAAeC2CEAAA8FoEIQAA4LUIQgAAwGsRhAAAgNciCAEAAK/1/wEWr9KAXnWGHgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint ./trained_model\n",
            "village leeker. lily lovered the every inspires. lily ecame a became a hope. they her every day boun new shappirose. they’s seconcis wagh of orf a dindess. the geniey kined ther wishes. lily was astonished and grateful. her first wish was for a friend. the fairy smiled and waved her wand. a small pupy appeared lily’s feet. lily named the pupy max. max and lily became best friends. they played together ev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g1UByDkh8ZAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}